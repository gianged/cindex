# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this
repository.

## Project Overview

**cindex** is a Model Context Protocol (MCP) server that provides semantic code search and context
retrieval for large codebases (1M+ LoC). It integrates with Claude Code to enable intelligent code
discovery through vector embeddings, multi-stage retrieval, and dependency analysis.

**Package:** `@gianged/cindex` **Type:** MCP Server (TypeScript) **Main Purpose:** RAG
(Retrieval-Augmented Generation) for code understanding

## Key Technologies

- **MCP SDK:** `@modelcontextprotocol/sdk` - MCP server framework
- **Database:** PostgreSQL 16+ with pgvector extension for vector similarity search
- **Embeddings:** Ollama (bge-m3:567m, 1024 dimensions)
- **LLM Summaries:** Ollama (qwen2.5-coder:7b, or 1.5b/3b for speed)
- **Code Parsing:** tree-sitter with 12 language parsers
  - Full support: TypeScript, JavaScript, Python, Java, Go, Rust, C, C++, C#, PHP, Ruby, Kotlin
  - Fallback parsing: Swift and other languages (regex-based)
- **YAML/Config Parsing:** js-yaml for Docker Compose, serverless configs
- **Vector Index:** HNSW (Hierarchical Navigable Small World) for production

## Development Commands

```bash
# Build the project
npm run build

# Development mode (watch for changes)
npm run dev

# Run tests
npm test

# Lint code
npm run lint

# Format code
npm run format

# Start the MCP server (after build)
npm start
```

## Architecture Overview

### Multi-Project Support

**cindex supports three deployment patterns:**

1. **Single Repository** - Traditional RAG for one codebase (base implementation)
2. **Multi-Project** - Index multiple independent repositories, search globally or per-repo
3. **Monorepo/Microservices** - Support workspace packages, service boundaries, and API contracts

**See `docs/overview.md` Section 1.5 for complete multi-project architecture documentation.**

### Multi-Stage Retrieval Pipeline

**Base Pipeline (Single Repository):** 4-stage retrieval approach:

1. **File-Level Retrieval:** Find relevant files using summary embeddings
2. **Chunk-Level Retrieval:** Locate specific code chunks (functions/classes) within files
3. **Symbol Resolution:** Resolve imported symbols and their definitions
4. **Import Chain Expansion:** Build dependency graph with depth limits (max 3 levels)

**Enhanced Pipeline (Multi-Project):** 7-stage retrieval with additional stages:

0. **Scope Filtering:** Filter by repository/service based on search scope (global, repo, service,
   boundary-aware)
1. **File-Level Retrieval** (with repo_id filtering)
2. **Chunk-Level Retrieval** (with repo_id/service_id filtering)
3. **Symbol Resolution** (cross-repository aware)
4. **Import Chain Expansion** (cross-repository dependencies)
5. **API Contract Enrichment:** Include REST/GraphQL/gRPC API definitions
6. **Deduplication** (cross-repository aware)
7. **Context Assembly** (grouped by repository with dependency relationships)

### Indexing Pipeline

1. **File Discovery:** Walk directory tree respecting .gitignore
2. **Parsing:** Tree-sitter for syntax-aware chunking (regex fallback for unsupported languages)
3. **Chunking:** Extract functions, classes, and logical blocks (50-500 lines each)
4. **Summary Generation:** LLM-based file summaries using qwen2.5-coder
5. **Embedding:** Generate vectors via Ollama bge-m3:567m
6. **Storage:** PostgreSQL with pgvector extension

### MCP Tools

**Core Tools (4 Base):**

- `search_codebase` - Semantic search with 9-stage retrieval pipeline
- `get_file_context` - Full context for specific file with dependencies
- `find_symbol_definition` - Locate function/class/variable definitions
- `index_repository` - Index or re-index codebase (incremental by default)

**Specialized Tools (9 Multi-Project/Management):**

- `list_indexed_repos` - List all indexed repositories with metadata
- `list_workspaces` - List workspaces in monorepo with dependencies
- `list_services` - List services across repos with API endpoints
- `get_workspace_context` - Get full workspace context with dependencies
- `get_service_context` - Get service context with API contracts
- `find_cross_workspace_usages` - Track workspace package usages
- `find_cross_service_calls` - Identify inter-service API calls
- `search_api_contracts` - Search REST/GraphQL/gRPC API endpoints
- `delete_repository` - Delete repositories and all associated data

**Multi-Project Features:**

- **Scope Filtering:** Global, repository, service, boundary-aware modes
- **Reference Repository Support:** Index and search framework documentation
- **API Contract Enrichment:** Semantic search for endpoints with implementation links
- **Cross-Repository Dependencies:** Track service calls and workspace usage
- **Progress Notifications:** Real-time 9-stage pipeline tracking

### Reference Repository Support

**cindex supports indexing external frameworks and libraries for learning and reference:**

**Repository Types:**

1. **`monolithic`** - Standard single-application repository (your code)
2. **`microservice`** - Individual microservice repository (your code)
3. **`monorepo`** - Multi-package repository with workspaces (your code)
4. **`library`** - Shared library repository (your own libraries)
5. **`reference`** - External framework/library cloned for learning (e.g., NestJS, React)
6. **`documentation`** - Markdown documentation files (e.g., /docs/libraries/)

**Reference Repository Behavior (`repo_type = 'reference'`):**

- **Lightweight indexing:** Skips workspace detection, service detection, API parsing
- **Excluded from default search:** Won't appear unless explicitly included
- **Lower priority:** Results prioritized below your own code (priority: 0.6 vs 1.0)
- **No cross-linking:** Never auto-linked to your main code dependencies
- **Version tracking:** Supports versioned re-indexing for framework updates

**Documentation Repository Behavior (`repo_type = 'documentation'`):**

- **Markdown-only:** Indexes markdown files, extracts code blocks
- **Fast indexing:** No LLM summaries, very lightweight (1000 files/min)
- **Lowest priority:** Results prioritized below all code (priority: 0.5)
- **Sectioned chunking:** Preserves markdown structure (headings, code blocks)

**Search Behavior:**

- **Default search:** Excludes `reference` and `documentation` repos automatically
- **Include references:** Use `include_references: true` to search framework code
- **Include documentation:** Use `include_documentation: true` to search markdown docs
- **Result grouping:** Results grouped by type (primary code, libraries, references, documentation)
- **Context limits:** Max 5 reference results, max 3 documentation results

**Version Tracking and Re-indexing:**

- Store version in metadata:
  `{ version: 'v10.3.0', upstream_url: 'https://github.com/nestjs/nest' }`
- Automatic re-index decision when version changes
- Use `force_reindex: true` to override version check
- Track last_indexed timestamp for outdated detection

## Current Implementation Status

**What's Complete:** ✅

- **Database Schema** - All tables created with multi-project support (Phase 1: 100%)
- **Type System** - Complete TypeScript type definitions (Phase 1: 100%)
- **Base Indexing** - File discovery, parsing, chunking (Phase 2: 100%)
  - File walker with .gitignore support ✅
  - Tree-sitter parsing for supported languages ✅
  - Semantic chunking (functions, classes, blocks) ✅
  - Metadata extraction (imports, exports, complexity) ✅
  - Workspace detection for monorepos ✅
  - Service detection for microservices ✅
  - Alias resolution (tsconfig paths, npm workspaces) ✅
  - Indexing strategies by repo type ✅
  - Markdown documentation indexing ✅
- **Version Tracking** - Reference repository versioning (Phase 2: 100%)
  - `getRepositoryVersion()`, `updateRepositoryVersion()` ✅
  - `shouldReindex()` with version comparison ✅
  - `clearRepositoryData()` for full re-index ✅
  - `deleteRepository()` with statistics ✅
  - `upsertRepository()`, `getIndexingStats()` ✅
  - `listIndexedRepositories()`, `listReferenceRepositories()` ✅
  - `isRepositoryOutdated()` ✅
- **Embeddings & Summaries** (Phase 3: 100%)
  - LLM summary generation via Ollama ✅
  - Embedding generation (bge-m3:567m) ✅
  - Symbol extraction and indexing ✅
  - Database persistence with batch optimization ✅
  - Progress tracking with ETA calculation ✅
  - Pipeline orchestrator ✅
  - API contract parsing (REST/GraphQL/gRPC) ✅
- **Language Support Expansion** (Phase 3.2: 100%)
  - C# tree-sitter support (full parsing) ✅
  - PHP tree-sitter support (v0.23.12, compatible) ✅
  - Ruby tree-sitter support (v0.21.0, compatible) ✅
  - Kotlin tree-sitter support (v0.3.8) ✅
  - Swift build issues documented (requires tree-sitter-cli) ✅
  - Total: 12 languages with full tree-sitter parsing ✅
- **Project Structure Detection** (Phase 3.3: 100%)
  - Docker Compose parsing with js-yaml ✅
  - Full Docker config extraction (ports, networks, volumes, dependencies) ✅
  - Serverless framework detection (Serverless Framework, Vercel, Netlify, AWS SAM, AWS CDK) ✅
  - Mobile project detection (React Native, Expo, Flutter, Capacitor, Ionic) ✅
  - Service type classification (docker, serverless, mobile) ✅
- **Multi-Stage Retrieval** (Phase 4: 100%)
  - 9-stage retrieval pipeline (upgraded from 5-stage) ✅
  - Stage 0: Scope filtering (global, repository, service, boundary-aware) ✅
  - Stage 1: Query processing with embedding cache ✅
  - Stage 2: File-level retrieval (scope-filtered SQL queries) ✅
  - Stage 3: Chunk-level retrieval (scope-filtered) ✅
  - Stage 4: Symbol resolution ✅
  - Stage 5: Import chain expansion ✅
  - Stage 6: API contract enrichment (semantic search, scope-aware) ✅
  - Stage 7: Deduplication ✅
  - Stage 8: Context assembly ✅
- **MCP Tools** (Phase 5: 100%)
  - MCP server framework with lifecycle management ✅
  - All 13 tools implemented and registered ✅
  - 4 core tools: search_codebase, get_file_context, find_symbol, index_repository ✅
  - 9 specialized tools: list_indexed_repos, list_workspaces, list_services, get_workspace_context, get_service_context, find_cross_workspace_usages, find_cross_service_calls, search_api_contracts, delete_repository ✅
  - Complete input validation (validator.ts - 514 lines) ✅
  - Complete output formatting (formatter.ts - 1,130 lines) ✅
  - Error handling with user-friendly messages ✅
  - Multi-project support (monorepo, microservices, reference repos) ✅
  - Integration tests (search-pipeline.test.ts - 423 lines) ✅
  - Progress notifications for indexing pipeline (9-stage tracking) ✅
  - Line-level import tracking in find_cross_workspace_usages ✅
  - Boundary-aware import filtering in get_file_context ✅
  - Service API endpoints fetching in list_services ✅
  - Workspace dependencies fetching in list_workspaces ✅
  - E2E testing with Claude Code (pending manual verification) ⚠️
- **Performance Optimizations** (Beyond Phase 5 scope)
  - LRU caching system (cache.ts - 288 lines) ✅
  - Query embedding cache (30 min TTL, 500 entries) ✅
  - Search result cache (5 min TTL, 200 entries) ✅
  - API endpoint cache (10 min TTL, 100 entries) ✅
  - Cache statistics and monitoring ✅
  - 9-stage progress notifications ✅
  - Performance: Cached queries ~50ms vs ~800ms uncached ✅
  - 80%+ reduction in Ollama API calls ✅

**What's Planned:** ⚠️
- **Optimization** (Phase 6: ~30% complete)
  - ~~Query caching (embeddings + results)~~ ✅ **Complete**
  - Incremental indexing (hash comparison logic) ⚠️
  - HNSW index optimization ⚠️
  - Edge case handling ⚠️
  - Performance monitoring ⚠️
  - Scale testing ⚠️

**Overall Completion: ~92%**

- Phase 1: ✅ 100% Complete (Database Schema & Types)
- Phase 2: ✅ 100% Complete (Base Indexing & Version Tracking)
- Phase 3: ✅ 100% Complete (Embeddings, Language Support, Project Detection)
- Phase 4: ✅ 100% Complete (Multi-Stage Retrieval - 9-stage pipeline)
- Phase 5: ✅ 100% Complete (MCP Tools - 13/13 tools with full features)
- Phase 6: ⚠️ ~30% Complete (Optimization - caching complete)

See `docs/tasks/phase-*.md` for detailed task breakdowns and checklists.

## Project Structure

```
src/
├── index.ts              # MCP server entry point
├── indexing/             # Code indexing pipeline
│   ├── file-walker.ts    # Directory traversal with .gitignore support
│   ├── chunker.ts        # Semantic code chunking (tree-sitter)
│   ├── parser.ts         # Tree-sitter code parsing
│   ├── metadata.ts       # File metadata extraction
│   ├── workspace-detector.ts  # Monorepo workspace detection
│   ├── service-detector.ts    # Microservice detection
│   ├── alias-resolver.ts      # Import alias resolution
│   ├── indexing-strategy.ts   # Repository type indexing strategies
│   ├── markdown-indexer.ts    # Markdown documentation indexing
│   ├── version-tracker.ts     # Version tracking and re-indexing
│   ├── summary.ts        # LLM-based file summary generation
│   ├── embeddings.ts     # Embedding generation with enhanced text
│   ├── symbols.ts        # Symbol extraction and embedding
│   └── orchestrator.ts   # Pipeline coordination (Phases 1-3)
├── retrieval/            # Search and retrieval
│   ├── vector-search.ts  # pgvector similarity search with scope filtering
│   └── deduplicator.ts   # Result prioritization and deduplication
├── database/             # PostgreSQL client
│   ├── client.ts         # Connection pool management
│   └── writer.ts         # Database persistence with batch optimization
├── mcp/                  # MCP tool implementations (future)
│   ├── search-codebase.ts
│   ├── get-file-context.ts
│   ├── find-symbol.ts
│   └── index-repository.ts
├── types/                # TypeScript type definitions
│   ├── database.ts       # Database schema types
│   ├── config.ts         # Configuration types
│   ├── workspace.ts      # Workspace detection types
│   ├── service.ts        # Service detection types
│   ├── indexing.ts       # Indexing pipeline types
│   └── mcp-tools.ts      # MCP tool types
├── utils/                # Shared utilities
│   ├── ollama.ts         # Ollama API client
│   ├── logger.ts         # Logging utilities
│   ├── errors.ts         # Error handling
│   └── progress.ts       # Progress tracking with ETA
└── config/               # Configuration
    └── env.ts            # Environment variable handling

tests/
├── unit/                 # Unit tests
├── integration/          # Integration tests
├── e2e/                  # End-to-end tests
├── fixtures/             # Test data
└── helpers/              # Test utilities
```

## Database Schema (database.sql)

### Base Tables (Single Repository)

Three main tables with vector indexes:

- **`code_chunks`:** Core embeddings for code chunks (functions, classes, blocks)
- **`code_files`:** File-level metadata with summaries and SHA256 hashes
- **`code_symbols`:** Symbol registry for function/class/variable lookups

### Multi-Project Tables (Extension)

Additional tables for multi-project/monorepo/microservice support:

- **`repositories`:** Multi-repository registry (repo_id, repo_type, workspace_config)
- **`services`:** Service registry with API contracts (service_id, service_type, api_endpoints
  JSONB)
- **`workspaces`:** Monorepo package/workspace tracking (workspace_id, package_name, tsconfig_paths)
- **`workspace_aliases`:** Import alias resolution (@workspace/pkg → filesystem path)
- **`cross_repo_dependencies`:** Cross-service dependency tracking (source→target, api_contracts)
- **`workspace_dependencies`:** Internal monorepo dependencies

**Column Extensions:** All base tables (`code_chunks`, `code_files`, `code_symbols`) have additional
columns:

- `repo_id` - Repository identifier for filtering
- `workspace_id` - Workspace identifier (monorepos)
- `package_name` - Package name from package.json
- `service_id` - Service identifier (microservices)

**Important:** Vector dimensions (1024) must match the embedding model. If changing
`EMBEDDING_MODEL` in MCP config, update all `vector(1024)` declarations in database.sql.

## Configuration via Environment Variables

All settings are configured through environment variables in the MCP config file
(`~/.config/claude/mcp.json`):

### Model Settings

- `EMBEDDING_MODEL` (default: bge-m3:567m)
- `EMBEDDING_DIMENSIONS` (default: 1024)
- `EMBEDDING_CONTEXT_WINDOW` (default: 4096, range: 512-131072) - Token limit for embedding model
- `SUMMARY_MODEL` (default: qwen2.5-coder:7b)
- `SUMMARY_CONTEXT_WINDOW` (default: 4096, range: 512-131072) - Token limit for summary model
- `OLLAMA_HOST` (default: http://localhost:11434)

**Context Window Notes:**
- Default 4096 matches Ollama's default and is sufficient (cindex only uses first 100 lines per file)
- Higher values consume more VRAM and are slower to process
- bge-m3:567m supports up to 8K tokens
- qwen2.5-coder:7b supports up to 32K tokens
- Only increase if you encounter issues with large files or need more context
- With 8GB VRAM (RTX 4060), you can comfortably use 4K-32K context windows

### Database Settings

- `POSTGRES_HOST` (default: localhost)
- `POSTGRES_PORT` (default: 5432)
- `POSTGRES_DB` (default: cindex_rag_codebase)
- `POSTGRES_USER` (default: postgres)
- `POSTGRES_PASSWORD` (required)

### Accuracy/Performance Tuning

- `HNSW_EF_SEARCH` (default: 300) - Higher = more accurate, slower
- `HNSW_EF_CONSTRUCTION` (default: 200) - Higher = better index quality
- `SIMILARITY_THRESHOLD` (default: 0.75) - Minimum similarity for retrieval
- `DEDUP_THRESHOLD` (default: 0.92) - Similarity threshold for deduplication

## MCP Server Configuration Scopes

**Three scopes:** User (`~/.claude.json`), Project (`.mcp.json`), Local (temporary)

**Scope priority:** Local > Project > User

**Project scope example** (`.mcp.json` - version controlled, team-shared):
```json
{
  "mcpServers": {
    "cindex": {
      "command": "node",
      "args": ["./dist/index.js"],
      "env": {
        "POSTGRES_HOST": "${POSTGRES_HOST:-localhost}",
        "POSTGRES_PASSWORD": "${POSTGRES_PASSWORD}"
      }
    }
  }
}
```

**Security:** Use `${VAR_NAME:-default}` expansion, never commit secrets

## Key Implementation Details

### Incremental Indexing

- SHA256 hash per file stored in `code_files.file_hash`
- On re-index: compare hashes, skip unchanged files
- Only re-embed modified files for fast updates

### Deduplication Strategy

- Post-retrieval comparison of chunk embeddings
- If similarity >0.92: keep highest-scoring chunk, discard duplicates
- Prevents utility function pollution in results

### Context Window Management

- Token estimation: ~4 chars = 1 token
- Warn if context >100k tokens (no hard limit)
- Token counts stored in `code_chunks.token_count`

### Import Chain Traversal

- Maximum depth: 3 levels (prevent runaway expansion)
- Circular import detection via visited files tracking
- Mark truncated chains in metadata

### Large File Handling

- <1000 lines: Normal chunking
- 1000-5000 lines: Section-based chunking
- > 5000 lines: Structure-only indexing (summary + exports)

### Tree-sitter Fallback

- Use regex-based chunking if tree-sitter fails
- 200-line sliding window with 20-line overlap
- Mark chunks as `chunk_type: 'fallback'`

## Testing Strategy

When writing tests:

- **Unit tests:** Test each stage independently (chunking, embedding, retrieval)
- **Integration tests:** End-to-end query flow
- **Scale tests:** Test with small (1k LoC), medium (50k LoC), and large (1M+ LoC) codebases
- **Edge cases:** Circular imports, large files, minified code, unsupported languages

Use test fixtures in `tests/fixtures/` for consistent test data.

## Performance Targets

### Accuracy-First Mode (Default)

- **Indexing:** 300-600 files/min (slower due to LLM summaries)
- **Query time:** <800ms
- **Relevance:** >92% in top 10 results
- **Context noise:** <2%

### Speed-First Mode (Alternative)

Set `SUMMARY_MODEL=qwen2.5-coder:1.5b` (speed optimization), `HNSW_EF_SEARCH=100`, `SIMILARITY_THRESHOLD=0.70`

- **Indexing:** 500-1000 files/min
- **Query time:** <500ms
- **Relevance:** >85% in top 10 results

## Important Implementation Notes

### When Adding New Features

1. **Configuration:** Add environment variables to `src/config/env.ts` with sensible defaults
2. **Database Changes:** Update `database.sql` and add migration logic
3. **MCP Tools:** Follow existing tool patterns in `src/mcp/`
4. **Testing:** Add unit tests in `tests/unit/`, integration tests in `tests/integration/`
5. **Documentation:** Update README.md for user-facing changes, this file for implementation details

### Code Quality Standards

- Use TypeScript strict mode (already configured in tsconfig.json)
- Add JSDoc comments for all exported functions
- Follow existing code patterns (arrow functions, async/await)
- Run `npm run lint` and `npm run format` before committing

### Import Conventions

**Path aliases:** Use `@config/*`, `@database/*`, `@indexing/*`, `@retrieval/*`, `@mcp/*`, `@types/*`, `@utils/*` - never relative imports

**Import order:** External packages → (blank line) → Internal imports → (blank line) → Type-only imports

**Key rules:**
- MCP SDK imports: Include `.js` extension (ESM requirement)
- Internal imports: NO extensions (.ts, .js)
- Node.js built-ins: Use `node:` prefix (`node:fs/promises`, `node:path`)
- Type imports: Use inline `type` keyword (`import { type Config } from '@config/env'`)
- Combine duplicate imports from same module

**Example:**
```typescript
// External (MCP SDK with .js)
import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';

// Internal (path aliases, no extension)
import { loadConfig } from '@config/env';
import { type ParseResult } from '@/types/indexing';

// Node.js built-ins (node: prefix)
import { randomUUID } from 'node:crypto';
```

**See [docs/syntax.md](docs/syntax.md) for MCP SDK, pgvector, and tree-sitter syntax references.**

### Database Operations

- Always use parameterized queries to prevent SQL injection
- Use connection pooling (configured in `src/database/client.ts`)
- Handle vector dimension mismatches gracefully with clear error messages
- Monitor HNSW index build progress for large datasets (15-45 min for 1M vectors)

### Ollama Integration

- Always check model availability before generating embeddings/summaries
- Implement retry logic for temporary failures
- Batch embedding requests (e.g., 100 files at a time)
- Fall back to rule-based summaries if LLM unavailable

### Error Handling

- Provide clear error messages with context (file path, operation, model name)
- Log errors with appropriate severity levels
- Handle common errors: PostgreSQL connection failures, Ollama unavailable, vector dimension
  mismatches
- Never fail silently - always inform user of issues

## Development Workflow

**Setup:**
```bash
sudo apt install postgresql-16 postgresql-16-pgvector
curl https://ollama.ai/install.sh | sh && ollama pull bge-m3:567m qwen2.5-coder:7b
createdb cindex_rag_codebase_dev && psql cindex_rag_codebase_dev < database.sql
npm install && npm run build
```

**Local testing:** Configure in `~/.config/claude/mcp.json` with path to `./dist/index.js`

**Debugging:** Use `console.error()` for MCP stderr, check MCP logs in Claude Code settings

## Reference Repository Usage Examples

**Index reference framework:**
```typescript
await index_repository({
  repo_path: '/references/nestjs',
  repo_id: 'nestjs-v10',
  repo_type: 'reference',
  metadata: { upstream_url: 'https://github.com/nestjs/nest', version: 'v10.3.0' }
});
```

**Search with references:**
```typescript
await search_codebase({
  query: 'how to implement guards',
  scope: 'global',
  include_references: true  // Include framework examples
});
// Returns: Your code (priority 1.0) + reference code (priority 0.6)
```

## Common Pitfalls to Avoid

1. **Vector Dimension Mismatch:** Always ensure `EMBEDDING_DIMENSIONS` matches the model output
2. **Memory Issues:** Batch large operations (don't load entire codebase into memory)
3. **HNSW Build Time:** Show progress for index builds >1M vectors (15-45 min)
4. **Circular Imports:** Always track visited files to prevent infinite loops
5. **Token Overflow:** Warn users early if context exceeds 100k tokens
6. **Large Files:** Don't try to embed 10k+ line files - use structure-only indexing

## Multi-Project Development Guidance

**Key Principles:**
- Always require `repo_id` for multi-project operations
- Implement scope filtering in retrieval pipeline Stage 0
- Use parameterized queries with `repo_id = ANY($1)` filters
- Cross-language communication = API calls, not imports
- Build incrementally: basic indexing → scoped search → dependency detection → API contracts

**Detailed implementation guidance:** See `docs/overview.md` Section 1.5 for multi-project architecture, API contract parsing patterns, workspace alias resolution, cross-repo deduplication, and multi-language monorepo handling.

## Additional Resources

- **Implementation Plan:** See `docs/overview.md` for complete technical specification
- **README:** User-facing documentation and quick start guide
- **CONTRIBUTING:** Guidelines for contributing to the project
- **Database Schema:** `database.sql` with detailed comments
